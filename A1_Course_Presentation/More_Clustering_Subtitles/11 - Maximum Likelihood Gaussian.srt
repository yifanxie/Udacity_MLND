1
00:00:00,180 --> 00:00:01,569
>> So one of the things that is going to be helpful as

2
00:00:01,569 --> 00:00:04,880
a subcomponent to this process is to be able to say. Well,

3
00:00:04,880 --> 00:00:07,120
if we've got a set of points in some space, and we're

4
00:00:07,120 --> 00:00:11,790
trying to find the maximum likelihood Gaussian with some known variant. Mode is

5
00:00:11,790 --> 00:00:14,620
the maximum likelihood Gaussian. What is the best way of setting the

6
00:00:14,620 --> 00:00:18,860
mean to capture this set of points? So fortunately this is really easy

7
00:00:18,860 --> 00:00:22,530
to do. And the reason that it works out this way is

8
00:00:22,530 --> 00:00:25,500
the same reason that we've talked about in several of the other lessons.

9
00:00:25,500 --> 00:00:28,770
But the maximum likelihood mean of the Gaussian, this mu that we want

10
00:00:28,770 --> 00:00:31,490
to set, is the mean of the data, the mean is the mean.

11
00:00:31,490 --> 00:00:33,350
>> That's pretty mean.

12
00:00:33,350 --> 00:00:35,700
>> And it's no mean feat that it works out this way.

13
00:00:35,700 --> 00:00:36,355
>> [LAUGH]

14
00:00:36,355 --> 00:00:39,170
>> And, [LAUGH] what?

15
00:00:39,170 --> 00:00:40,960
>> Oh, just well done.

16
00:00:40,960 --> 00:00:44,600
>> So, in particular, this is really easy to compute. If we know that all

17
00:00:44,600 --> 00:00:47,070
this data is coming from the same Gaussian,

18
00:00:47,070 --> 00:00:50,640
then finding the mean that maximizes the likelihood

19
00:00:50,640 --> 00:00:52,800
is just computing the mean of all the points.

20
00:00:52,800 --> 00:00:55,380
>> Right, we kind of did that, just a few slides ago.

21
00:00:55,380 --> 00:00:56,740
>> Exactly.

22
00:00:56,740 --> 00:00:58,510
>> Okay, alright, so given a bunch of data

23
00:00:58,510 --> 00:01:00,920
points that I all know came from some Gaussian, I

24
00:01:00,920 --> 00:01:04,180
can compute the mean of that Gaussian by actually

25
00:01:04,180 --> 00:01:06,900
taking the sample mean, and I could mean it, okay.

26
00:01:06,900 --> 00:01:10,090
>> So the tricky thing of course, is what happens if there's k of them. How

27
00:01:10,090 --> 00:01:15,700
do we set the k different means? And our answer is going to be, there I just

28
00:01:15,700 --> 00:01:18,180
wrote it. Do you see it?

29
00:01:18,180 --> 00:01:18,555
>> Nope.

30
00:01:18,555 --> 00:01:21,830
>> That's because, it's hidden variables!

31
00:01:21,830 --> 00:01:24,470
>> Oh. My favorite kind of variables.

32
00:01:24,470 --> 00:01:26,850
>> Variables that you don't have to see. So what we're going to imagine is

33
00:01:26,850 --> 00:01:30,700
that the data points, instead of just being x, it's actually x and a bunch of

34
00:01:30,700 --> 00:01:32,910
random variables that are indicator variables on which

35
00:01:32,910 --> 00:01:36,240
cluster that x came from. So it's not

36
00:01:36,240 --> 00:01:40,080
just x anymore it's x and let's say a bunch of zeros and then a one.

37
00:01:40,080 --> 00:01:45,510
Corresponding to which cluster generated X. Now of course if we knew that, that

38
00:01:45,510 --> 00:01:47,290
would be really useful information. We, we're

39
00:01:47,290 --> 00:01:49,100
going to have to do some inference to

40
00:01:49,100 --> 00:01:51,530
figure out what those values are. But,

41
00:01:51,530 --> 00:01:56,530
the, concept is that, by adding these extra

42
00:01:56,530 --> 00:01:58,010
hidden variables in, it really kind of

43
00:01:58,010 --> 00:01:59,570
breaks up the problem in a convenient way.

44
00:01:59,570 --> 00:02:00,440
>> Okay.

